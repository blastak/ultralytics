#!/usr/bin/env python3
"""
QBB ì¥ê¸° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
1944ê°œ í†µí•© ë²ˆí˜¸íŒ ë°ì´í„°ì…‹ìœ¼ë¡œ 100 epochs í•™ìŠµ
"""

import sys
import torch
import time
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

sys.path.insert(0, '/workspace/repo/ultralytics')
from ultralytics import YOLO


def setup_training_environment():
    """í•™ìŠµ í™˜ê²½ ì„¤ì •"""
    print("ğŸ”§ Setting up training environment...")
    
    # CUDA í™•ì¸
    print(f"ğŸ–¥ï¸  CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"ğŸš€ GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
    work_dir = Path.cwd()
    print(f"ğŸ“ Working directory: {work_dir}")
    
    # ë°ì´í„°ì…‹ í™•ì¸
    dataset_yaml = Path('datasets/unified_license_plates/unified_license_plates.yaml')
    if not dataset_yaml.exists():
        raise FileNotFoundError(f"Dataset YAML not found: {dataset_yaml}")
    
    print(f"ğŸ“Š Dataset YAML: {dataset_yaml}")
    
    return dataset_yaml


def train_qbb_long():
    """QBB ì¥ê¸° í•™ìŠµ ì‹¤í–‰"""
    
    print("ğŸš€ Starting QBB Long Training Session")
    print("=" * 50)
    
    # í™˜ê²½ ì„¤ì •
    dataset_yaml = setup_training_environment()
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ“¦ Loading QBB model...")
    model = YOLO('yolo11n-qbb.yaml')
    
    print(f"âœ… QBB model loaded successfully")
    print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.model.parameters()):,}")
    
    # í•™ìŠµ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # ê³ ê¸‰ í•™ìŠµ ì„¤ì •
    training_config = {
        'data': str(dataset_yaml),
        'epochs': 100,              # ì¥ê¸° í•™ìŠµ
        'imgsz': 640,               # í‘œì¤€ ì´ë¯¸ì§€ í¬ê¸°
        'batch': 8,                 # GPU ë©”ëª¨ë¦¬ ê³ ë ¤
        'device': 0 if torch.cuda.is_available() else 'cpu',
        'workers': 4,               # ë°ì´í„° ë¡œë”© ì›Œì»¤
        'patience': 20,             # ì¡°ê¸° ì¤‘ë‹¨ ì„ê³„ê°’
        'save': True,               # ëª¨ë¸ ì €ì¥
        'plots': True,              # í”Œë¡¯ ìƒì„±
        'val': True,                # ê²€ì¦ ì‹¤í–‰
        'project': 'runs/qbb',      # ê²°ê³¼ ì €ì¥ ìœ„ì¹˜
        'name': 'unified_training', # ì‹¤í—˜ ì´ë¦„
        'exist_ok': True,           # ê¸°ì¡´ ì‹¤í—˜ ë®ì–´ì“°ê¸°
        'verbose': True,            # ìƒì„¸ ë¡œê·¸
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        'lr0': 0.01,                # ì´ˆê¸° í•™ìŠµë¥ 
        'lrf': 0.01,                # ìµœì¢… í•™ìŠµë¥  (cosine decay)
        'momentum': 0.937,          # SGD ëª¨ë©˜í…€
        'weight_decay': 0.0005,     # ê°€ì¤‘ì¹˜ ê°ì†Œ
        'warmup_epochs': 3.0,       # ì›Œë°ì—… ì—í¬í¬
        'warmup_momentum': 0.8,     # ì›Œë°ì—… ëª¨ë©˜í…€
        'warmup_bias_lr': 0.1,      # ì›Œë°ì—… í¸í–¥ í•™ìŠµë¥ 
        
        # ë°ì´í„° ì¦ê°•
        'hsv_h': 0.015,             # ìƒ‰ì¡° ì¦ê°•
        'hsv_s': 0.7,               # ì±„ë„ ì¦ê°•
        'hsv_v': 0.4,               # ëª…ë„ ì¦ê°•
        'degrees': 0.0,             # íšŒì „ ì¦ê°• (ë²ˆí˜¸íŒì€ íšŒì „ ìµœì†Œí™”)
        'translate': 0.1,           # ì´ë™ ì¦ê°•
        'scale': 0.5,               # í¬ê¸° ì¦ê°•
        'shear': 0.0,               # ì „ë‹¨ ì¦ê°• (ë²ˆí˜¸íŒ í˜•íƒœ ë³´ì¡´)
        'perspective': 0.0,         # ì›ê·¼ ì¦ê°• (í˜•íƒœ ë³´ì¡´)
        'flipud': 0.0,              # ìƒí•˜ ë°˜ì „ (ë²ˆí˜¸íŒ íŠ¹ì„±ìƒ ë¹„í™œì„±í™”)
        'fliplr': 0.5,              # ì¢Œìš° ë°˜ì „
        'mosaic': 1.0,              # ëª¨ìì´í¬ ì¦ê°•
        'mixup': 0.0,               # ë¯¹ìŠ¤ì—… (OBBì—ì„œëŠ” ë¹„í™œì„±í™”)
        'copy_paste': 0.0,          # ë³µì‚¬-ë¶™ì—¬ë„£ê¸° (OBBì—ì„œëŠ” ë¹„í™œì„±í™”)
        
        # ì •ê·œí™” ë° ì•ˆì •ì„±
        'box': 7.5,                 # ë°•ìŠ¤ ì†ì‹¤ ê°€ì¤‘ì¹˜
        'cls': 0.5,                 # ë¶„ë¥˜ ì†ì‹¤ ê°€ì¤‘ì¹˜
        'dfl': 1.5,                 # ë¶„í¬ ì´ˆì  ì†ì‹¤ ê°€ì¤‘ì¹˜
        
        # í‰ê°€ ì„¤ì •
        'iou': 0.7,                 # NMS IoU ì„ê³„ê°’
        'save_period': 10,          # ëª¨ë¸ ì €ì¥ ì£¼ê¸°
        'cache': False,             # ìºì‹œ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
        'amp': True,                # ìë™ í˜¼í•© ì •ë°€ë„
        'fraction': 1.0,            # ë°ì´í„°ì…‹ ì‚¬ìš© ë¹„ìœ¨
        'profile': False,           # í”„ë¡œíŒŒì¼ë§ ë¹„í™œì„±í™”
        'freeze': None,             # ë ˆì´ì–´ ë™ê²° ì—†ìŒ
        'multi_scale': False,       # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ë¹„í™œì„±í™”
        'overlap_mask': True,       # ë§ˆìŠ¤í¬ ì˜¤ë²„ë© í—ˆìš©
        'mask_ratio': 4,            # ë§ˆìŠ¤í¬ ë‹¤ìš´ìƒ˜í”Œë§ ë¹„ìœ¨
        'dropout': 0.0,             # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
    }
    
    print(f"\nâš™ï¸  Training Configuration:")
    print(f"  ğŸ“Š Dataset: unified_license_plates (1944 images)")
    print(f"  ğŸ¯ Epochs: {training_config['epochs']}")
    print(f"  ğŸ“¦ Batch size: {training_config['batch']}")
    print(f"  ğŸ–¼ï¸  Image size: {training_config['imgsz']}")
    print(f"  ğŸ§  Learning rate: {training_config['lr0']} â†’ {training_config['lrf']}")
    print(f"  â° Patience: {training_config['patience']}")
    print(f"  ğŸ² Device: {training_config['device']}")
    
    try:
        print(f"\nğŸš€ Starting training...")
        results = model.train(**training_config)
        
        # í•™ìŠµ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
        end_time = time.time()
        training_duration = end_time - start_time
        hours = int(training_duration // 3600)
        minutes = int((training_duration % 3600) // 60)
        
        print(f"\nğŸ‰ QBB Long Training Completed Successfully!")
        print(f"â° Training duration: {hours}h {minutes}m")
        print(f"ğŸ“ Results saved in: runs/qbb/unified_training/")
        
        # ê²°ê³¼ ëª¨ë¸ ê²½ë¡œ
        best_model_path = Path('runs/qbb/unified_training/weights/best.pt')
        last_model_path = Path('runs/qbb/unified_training/weights/last.pt')
        
        if best_model_path.exists():
            print(f"ğŸ† Best model: {best_model_path}")
        if last_model_path.exists():
            print(f"ğŸ“Š Last model: {last_model_path}")
        
        # í•™ìŠµ ê²°ê³¼ ìš”ì•½
        print_training_summary(results, training_duration)
        
        return results, best_model_path
        
    except Exception as e:
        print(f"âŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def print_training_summary(results, duration):
    """í•™ìŠµ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print(f"\nğŸ“Š Training Summary:")
    print(f"=" * 30)
    
    try:
        # ê²°ê³¼ ê²½ë¡œì—ì„œ ë©”íŠ¸ë¦­ ì •ë³´ ì½ê¸°
        results_dir = Path('runs/qbb/unified_training')
        
        if (results_dir / 'results.csv').exists():
            import pandas as pd
            df = pd.read_csv(results_dir / 'results.csv')
            
            if not df.empty:
                last_epoch = df.iloc[-1]
                
                print(f"ğŸ“ˆ Final Metrics:")
                if 'metrics/mAP50(B)' in df.columns:
                    print(f"  ğŸ¯ mAP@0.5: {last_epoch.get('metrics/mAP50(B)', 'N/A'):.4f}")
                if 'metrics/mAP50-95(B)' in df.columns:
                    print(f"  ğŸ¯ mAP@0.5:0.95: {last_epoch.get('metrics/mAP50-95(B)', 'N/A'):.4f}")
                if 'train/box_loss' in df.columns:
                    print(f"  ğŸ“¦ Box Loss: {last_epoch.get('train/box_loss', 'N/A'):.4f}")
                if 'train/cls_loss' in df.columns:
                    print(f"  ğŸ·ï¸  Class Loss: {last_epoch.get('train/cls_loss', 'N/A'):.4f}")
                if 'val/box_loss' in df.columns:
                    print(f"  âœ… Val Box Loss: {last_epoch.get('val/box_loss', 'N/A'):.4f}")
                if 'val/cls_loss' in df.columns:
                    print(f"  âœ… Val Class Loss: {last_epoch.get('val/cls_loss', 'N/A'):.4f}")
    
    except Exception as e:
        print(f"  ğŸ“Š Metrics summary not available: {e}")
    
    print(f"â° Total training time: {duration/3600:.1f} hours")
    print(f"ğŸ“ All results saved in: runs/qbb/unified_training/")


def validate_trained_model(model_path):
    """í•™ìŠµëœ ëª¨ë¸ ê²€ì¦"""
    print(f"\nğŸ” Validating trained model: {model_path}")
    
    if not model_path.exists():
        print(f"âŒ Model not found: {model_path}")
        return
    
    try:
        model = YOLO(model_path)
        
        # ê²€ì¦ ì‹¤í–‰
        dataset_yaml = Path('datasets/unified_license_plates/unified_license_plates.yaml')
        results = model.val(data=str(dataset_yaml), verbose=True)
        
        print(f"âœ… Model validation completed")
        
    except Exception as e:
        print(f"âŒ Validation failed: {e}")


def main():
    print("ğŸš€ QBB Long Training Session")
    print("ğŸ“Š Dataset: Unified License Plates (1944 images)")
    print("ğŸ¯ Target: 100 epochs comprehensive training")
    print("=" * 60)
    
    # í•™ìŠµ ì‹¤í–‰
    results, best_model = train_qbb_long()
    
    if results and best_model:
        # ëª¨ë¸ ê²€ì¦
        validate_trained_model(best_model)
        
        print(f"\nğŸŠ QBB Long Training Session Completed!")
        print(f"ğŸ“ˆ Next steps:")
        print(f"1. Review training plots in runs/qbb/unified_training/")
        print(f"2. Run visualization script: python visualize_qbb_results.py")
        print(f"3. Test model performance on test set")
        print(f"4. Compare with OBB baseline performance")
        
    else:
        print(f"\nâŒ Training failed. Please check error messages above.")
        print(f"ğŸ’¡ Troubleshooting tips:")
        print(f"1. Check GPU memory availability")
        print(f"2. Verify dataset paths and formats")
        print(f"3. Review training configuration")


if __name__ == "__main__":
    main()